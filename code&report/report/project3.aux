\relax 
\providecommand\zref@newlabel[2]{}
\providecommand \oddpage@label [2]{}
\@writefile{toc}{\contentsline {section}{\numberline {1}Neural Network}{1}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces The training process of the provided code.}}{1}}
\newlabel{fig1}{{1}{1}}
\pgfsyspdfmark {pgfid1}{5317059}{15109479}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Network structure}{1}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Experiment on the number of neurons in the first layer.}}{2}}
\newlabel{fig2}{{2}{2}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Experiment on the depth (the number of hidden layers) of the model.}}{2}}
\newlabel{fig3}{{3}{2}}
\pgfsyspdfmark {pgfid2}{5317059}{48208051}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}Training procedure}{3}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Experiment with learning rate.}}{3}}
\newlabel{fig4}{{4}{3}}
\pgfsyspdfmark {pgfid3}{5317059}{19239582}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3}Vectorized evaluation}{3}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Notation and size for matrices.}}{4}}
\newlabel{tab1}{{1}{4}}
\@writefile{toc}{\contentsline {paragraph}{Forward evaluation}{4}}
\@writefile{toc}{\contentsline {paragraph}{Backpropagation}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4}Weight decay}{5}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Experiment with $l_2$ regularization coefficient $\lambda $.}}{5}}
\newlabel{fig5}{{5}{5}}
\pgfsyspdfmark {pgfid4}{4950088}{13670801}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.5}Softmax}{5}}
\@writefile{toc}{\contentsline {paragraph}{Forward evaluation}{6}}
\@writefile{toc}{\contentsline {paragraph}{Backpropagation}{6}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces New hyperparameters attained from experiments.}}{6}}
\newlabel{tab2}{{2}{6}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Model with softmax layer and cross entropy loss function.}}{7}}
\newlabel{fig6}{{6}{7}}
\pgfsyspdfmark {pgfid5}{5317059}{31969358}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.6}Bias}{7}}
\@writefile{toc}{\contentsline {paragraph}{1}{7}}
\@writefile{toc}{\contentsline {paragraph}{2}{7}}
\@writefile{toc}{\contentsline {paragraph}{3}{8}}
\@writefile{toc}{\contentsline {paragraph}{Results and analysis}{8}}
\pgfsyspdfmark {pgfid6}{5317059}{48208051}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.7}Dropout}{9}}
\pgfsyspdfmark {pgfid7}{5317059}{35799729}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.8}Fine-tuning of the last layer}{9}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.9}Extend data}{9}}
\pgfsyspdfmark {pgfid8}{5317059}{48208051}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces An image randomly selected from training set.}}{10}}
\newlabel{fig7}{{7}{10}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.10}Convolutional layer}{10}}
\@writefile{toc}{\contentsline {paragraph}{Forward evaluation}{10}}
\@writefile{toc}{\contentsline {paragraph}{Backpropagation}{11}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces The procedure to evaluate the gradient of the convolutional layer.}}{11}}
\newlabel{fig8}{{8}{11}}
\@writefile{toc}{\contentsline {paragraph}{Results and analyse}{11}}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Best hyperparameters chosen by experiments in CNN.}}{12}}
\newlabel{tab3}{{3}{12}}
\pgfsyspdfmark {pgfid9}{5317059}{40322767}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.11}Extra part: improvements}{12}}
\pgfsyspdfmark {pgfid10}{5317059}{8253645}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.12}Final model and results}{13}}
\@writefile{lot}{\contentsline {table}{\numberline {4}{\ignorespaces Hyperparameters in final model.}}{13}}
\newlabel{tab4}{{4}{13}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Change of cross-entropy when training in the final model.}}{13}}
\newlabel{fig9}{{9}{13}}
\pgfsyspdfmark {pgfid11}{5317059}{16333122}
\@writefile{toc}{\contentsline {section}{\numberline {2}Dimensionality Reduction}{14}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Centralization and Chosen of k}{14}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.1}Centralization}{14}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Left: eigenspectrum of uncentralized $X$. Right: eigenspectrum of centralized $X$.}}{14}}
\newlabel{fig10}{{10}{14}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.2}Chosen of k}{14}}
\pgfsyspdfmark {pgfid12}{5317059}{43438246}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Top 16 eigenvectors}{15}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces Left: projected images in uncentralized case. Right: projected images in centralized case.}}{15}}
\newlabel{fig11}{{11}{15}}
\@writefile{toc}{\contentsline {paragraph}{color}{15}}
\@writefile{toc}{\contentsline {paragraph}{shape}{15}}
\@writefile{toc}{\contentsline {paragraph}{order}{15}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}2D points}{16}}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces Project the data onto the top two eigenvectors. Left: uncentralized. Right: centralized.}}{16}}
\newlabel{fig12}{{12}{16}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}Reconstruction}{16}}
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces Recovered image. Left: uncentralized case. Center: origin image. Right: centralized case.}}{16}}
\newlabel{fig13}{{13}{16}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5}Reconstruction with noise}{17}}
\@writefile{lof}{\contentsline {figure}{\numberline {14}{\ignorespaces Reconstruction with noise. Left: origin image. Right: reconstructed image.}}{17}}
\newlabel{fig14}{{14}{17}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.6}LLE}{17}}
\@writefile{lof}{\contentsline {figure}{\numberline {15}{\ignorespaces LLE of swissroll.}}{17}}
\newlabel{fig15}{{15}{17}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Gaussian Mixture Model}{18}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}EM for Mixture of Gaussians}{18}}
\@writefile{toc}{\contentsline {paragraph}{E step}{18}}
\@writefile{toc}{\contentsline {paragraph}{Log-likelihood}{18}}
\@writefile{toc}{\contentsline {paragraph}{M step}{18}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Mixtures of Gaussians}{18}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Training}{18}}
\@writefile{lof}{\contentsline {figure}{\numberline {16}{\ignorespaces A random instance in training set for both digits 2 and 3.}}{19}}
\newlabel{fig16}{{16}{19}}
\@writefile{toc}{\contentsline {paragraph}{digits 2}{19}}
\@writefile{lof}{\contentsline {figure}{\numberline {17}{\ignorespaces $\qopname  \relax o{log}P(TrainingData)$ and clusters for the fist two dimensions.}}{19}}
\newlabel{fig17}{{17}{19}}
\@writefile{lof}{\contentsline {figure}{\numberline {18}{\ignorespaces Mean and variance of two clusters.}}{20}}
\newlabel{fig18}{{18}{20}}
\@writefile{lot}{\contentsline {table}{\numberline {5}{\ignorespaces Results for digits 2.}}{20}}
\newlabel{tab5}{{5}{20}}
\@writefile{toc}{\contentsline {paragraph}{digits 3}{20}}
\@writefile{lof}{\contentsline {figure}{\numberline {19}{\ignorespaces $\qopname  \relax o{log}P(TrainingData)$ and clusters for the fist two dimensions.}}{20}}
\newlabel{fig19}{{19}{20}}
\@writefile{lof}{\contentsline {figure}{\numberline {20}{\ignorespaces Mean and variance of two clusters.}}{21}}
\newlabel{fig20}{{20}{21}}
\@writefile{lot}{\contentsline {table}{\numberline {6}{\ignorespaces Results for digits 3.}}{21}}
\newlabel{tab6}{{6}{21}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}Initializing a mixture of Gaussians with k-means}{21}}
\@writefile{toc}{\contentsline {paragraph}{\textit  {kmeans.m and distmat.m}}{21}}
\@writefile{toc}{\contentsline {paragraph}{\textit  {mogEM.m}}{21}}
\@writefile{toc}{\contentsline {paragraph}{Train MoG models}{21}}
\@writefile{lof}{\contentsline {figure}{\numberline {21}{\ignorespaces Train with original initialization.}}{22}}
\newlabel{fig21}{{21}{22}}
\@writefile{lof}{\contentsline {figure}{\numberline {22}{\ignorespaces Train with kmeans initialization.}}{22}}
\newlabel{fig22}{{22}{22}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5}Classification using MoGs}{22}}
\@writefile{toc}{\contentsline {paragraph}{Answer to the questions on the paper:}{22}}
\@writefile{lof}{\contentsline {figure}{\numberline {23}{\ignorespaces Error rate for different number of components.}}{23}}
\newlabel{fig23}{{23}{23}}
